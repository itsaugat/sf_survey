{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96f4654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3dfa3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['age', 'workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race',\n",
    "                'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac038f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26540\n",
      "26540\n",
      "26540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/3d05xz69469g_qgyv9w2pdy40000gn/T/ipykernel_88149/2515983725.py:83: DeprecationWarning: NotImplemented should not be used in a boolean context\n",
      "  maha_pos_dist = list(filter((-9999).__ne__, maha_pos_dist))\n",
      "/var/folders/9d/3d05xz69469g_qgyv9w2pdy40000gn/T/ipykernel_88149/2515983725.py:84: DeprecationWarning: NotImplemented should not be used in a boolean context\n",
      "  maha_neg_dist = list(filter((-9999).__ne__, maha_neg_dist))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26540\n",
      "26540\n",
      "26540\n",
      "26540\n",
      "26540\n",
      "26540\n",
      "26540\n",
      "26540\n",
      "26540\n"
     ]
    }
   ],
   "source": [
    "sf_dict = {}\n",
    "num_k_sf_nh_dict = {}\n",
    "num_k_sf_nmotb_dict = {}\n",
    "l1_dist_dict = {}\n",
    "l2_dist_dict = {}\n",
    "maha_pos_dist_dict = {}\n",
    "maha_neg_dist_dict = {}\n",
    "feat_dict = {}\n",
    "\n",
    "for feature in feature_list:\n",
    "    \n",
    "    sf_val = []\n",
    "    feat = []\n",
    "    num_k_sf_nh = []\n",
    "    num_k_sf_nmotb = []\n",
    "    l1_dist = []\n",
    "    l2_dist = []\n",
    "    maha_pos_dist = []\n",
    "    maha_neg_dist = []\n",
    "    \n",
    "    high = feature+'_higher_mdn.pickle'\n",
    "    low = feature+'_lower_mdn.pickle'\n",
    "\n",
    "    with open(high, 'rb') as h:\n",
    "        results_high = pickle.load(h)\n",
    "\n",
    "    with open(low, 'rb') as l:\n",
    "        results_low = pickle.load(l)\n",
    "    \n",
    "    for i in range(len(results_high)):\n",
    "        for j in range(len(results_high[i])):\n",
    "            # what to do if the sf-value is same for high/low set?\n",
    "            # currently, if they are equal, taking the high set as SF\n",
    "            if results_high[i][j][0] > results_low[i][j][0]:\n",
    "                sf_val.append(results_high[i][j][0])\n",
    "                feat.append(results_high[i][j][1])\n",
    "                num_k_sf_nh.append(results_high[i][j][2])\n",
    "                num_k_sf_nmotb.append(results_high[i][j][3])\n",
    "                l1_dist.append(results_high[i][j][4])\n",
    "                l2_dist.append(results_high[i][j][5])\n",
    "                maha_pos_dist.append(results_high[i][j][6])\n",
    "                maha_neg_dist.append(results_high[i][j][7])\n",
    "                \n",
    "            elif results_high[i][j][0] < results_low[i][j][0]:\n",
    "                sf_val.append(results_low[i][j][0])\n",
    "                feat.append(results_low[i][j][1])\n",
    "                num_k_sf_nh.append(results_low[i][j][2])\n",
    "                num_k_sf_nmotb.append(results_low[i][j][3])\n",
    "                l1_dist.append(results_low[i][j][4])\n",
    "                l2_dist.append(results_low[i][j][5])\n",
    "                maha_pos_dist.append(results_low[i][j][6])\n",
    "                maha_neg_dist.append(results_low[i][j][7])\n",
    "            \n",
    "            elif results_high[i][j][0] == results_low[i][j][0]:\n",
    "                if results_high[i][j][1] >= results_low[i][j][1]:\n",
    "                    sf_val.append(results_high[i][j][0])\n",
    "                    feat.append(results_high[i][j][1])\n",
    "                    num_k_sf_nh.append(results_high[i][j][2])\n",
    "                    num_k_sf_nmotb.append(results_high[i][j][3])\n",
    "                    l1_dist.append(results_high[i][j][4])\n",
    "                    l2_dist.append(results_high[i][j][5])\n",
    "                    maha_pos_dist.append(results_high[i][j][6])\n",
    "                    maha_neg_dist.append(results_high[i][j][7])\n",
    "                elif results_high[i][j][1] < results_low[i][j][1]:\n",
    "                    sf_val.append(results_low[i][j][0])\n",
    "                    feat.append(results_low[i][j][1])\n",
    "                    num_k_sf_nh.append(results_low[i][j][2])\n",
    "                    num_k_sf_nmotb.append(results_low[i][j][3])\n",
    "                    l1_dist.append(results_low[i][j][4])\n",
    "                    l2_dist.append(results_low[i][j][5])\n",
    "                    maha_pos_dist.append(results_low[i][j][6])\n",
    "                    maha_neg_dist.append(results_low[i][j][7])\n",
    "                    \n",
    "    \n",
    "    print(len(sf_val))\n",
    "    \n",
    "    sf_val_avg = sum(sf_val) / len(sf_val)\n",
    "    sf_dict[feature] = sf_val_avg\n",
    "\n",
    "    # remove dummy values from the list\n",
    "    num_k_sf_nh = list(filter((-9999).__ne__, num_k_sf_nh))\n",
    "    num_k_sf_nmotb = list(filter((-9999).__ne__, num_k_sf_nmotb))\n",
    "    maha_pos_dist = list(filter((-9999).__ne__, maha_pos_dist))\n",
    "    maha_neg_dist = list(filter((-9999).__ne__, maha_neg_dist))\n",
    "\n",
    "    num_k_sf_nh_dict[feature] = sum(num_k_sf_nh) / len(num_k_sf_nh)\n",
    "    num_k_sf_nmotb_dict[feature] = sum(num_k_sf_nmotb) / len(num_k_sf_nmotb)\n",
    "    l1_dist_dict[feature] = sum(l1_dist) / len(l1_dist)\n",
    "    l2_dist_dict[feature] = sum(l2_dist) / len(l2_dist)\n",
    "    maha_pos_dist_dict[feature] = sum(maha_pos_dist) / len(maha_pos_dist)\n",
    "    maha_neg_dist_dict[feature] = sum(maha_neg_dist) / len(maha_neg_dist)\n",
    "\n",
    "    # get the num of feature diff count as counter object\n",
    "    feat_dict[feature] = collections.Counter(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcc45b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 1.7233672443732813,\n",
       " 'workclass': 1.7618220920192267,\n",
       " 'education': 1.8015616623707713,\n",
       " 'marital_status': 1.7638896757235114,\n",
       " 'occupation': 1.8306697967605488,\n",
       " 'relationship': 1.7658370268322994,\n",
       " 'race': 1.736260455920387,\n",
       " 'sex': 1.7823379804069672,\n",
       " 'capital_gain': 1.5392166029257013,\n",
       " 'capital_loss': 1.468257637700511,\n",
       " 'hours_per_week': 1.7307732822302295,\n",
       " 'country': 1.7528048985941689}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f72bb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workclass'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b9e5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'occupation'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_feature = max(sf_dict, key=sf_dict.get)\n",
    "key_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a2d0510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4540.614367085628"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_k_sf_nh_dict[key_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b8e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4281.263239655416"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_k_sf_nmotb_dict[key_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187e2a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.548305297706061"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_dist_dict[key_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7118f997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39202916515132497"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_dist_dict[key_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cce146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2517717374522244"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maha_pos_dist_dict[key_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a6abcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.849111160716791"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maha_neg_dist_dict[key_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "711b5f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 5127, 1: 8055, 2: 11833, 4: 1294, 5: 208, 6: 22, 7: 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict[key_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b9490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key_feature': 'occupation',\n",
       " 'sf_value': 1.8306697967605488,\n",
       " 'num_k_sf_nh': 4540.614367085628,\n",
       " 'num_k_sf_nmotb': 4281.263239655416,\n",
       " 'l1_dist': 0.548305297706061,\n",
       " 'l2_dist': 0.39202916515132497,\n",
       " 'maha_pos': 3.2517717374522244,\n",
       " 'maha_neg': 4.849111160716791}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store in dict\n",
    "agg_stat = {}\n",
    "\n",
    "agg_stat['key_feature'] = key_feature\n",
    "agg_stat['sf_value'] = sf_dict[key_feature]\n",
    "agg_stat['num_k_sf_nh'] = num_k_sf_nh_dict[key_feature]\n",
    "agg_stat['num_k_sf_nmotb'] = num_k_sf_nmotb_dict[key_feature]\n",
    "agg_stat['l1_dist'] = l1_dist_dict[key_feature]\n",
    "agg_stat['l2_dist'] = l2_dist_dict[key_feature]\n",
    "agg_stat['maha_pos'] = maha_pos_dist_dict[key_feature]\n",
    "agg_stat['maha_neg'] = maha_neg_dist_dict[key_feature]\n",
    "\n",
    "agg_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21fcd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feat_dict[key_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26226ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 8055, '2': 11833, '3+': 6652}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict = {}\n",
    "three = 0\n",
    "one = 0\n",
    "two = 0\n",
    "for key in feat:\n",
    "    if key>=3:\n",
    "        three += feat[key]\n",
    "    elif key == 1:\n",
    "        one = feat[key]\n",
    "    elif key == 2:\n",
    "        two = feat[key]\n",
    "\n",
    "new_dict['1'] = one\n",
    "new_dict['2'] = two\n",
    "new_dict['3+'] = three\n",
    "\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4539d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
